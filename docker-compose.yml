version: "3.9"

services:
  # This service runs the reverse proxy server for easier access to the other services.
  # It allows the use of more human-friendly domains instead of ports.
  traefik:
    profiles: [ "dagster", "mlflow", "triton" ]
    image: "traefik:v2.7"
    container_name: traefik
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik.rule=Host(`traefik.127.0.0.1.nip.io`)"
      - "traefik.http.routers.traefik.entrypoints=web"
      - "traefik.http.services.traefik.loadbalancer.server.port=8080"
    command:
      - "--log.level=DEBUG"
      - "--api.insecure=true"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entrypoints.web.address=:80"
    ports:
      - "80:80"
      - "8080:8080"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock:ro"
    networks:
      - mlops_bridge

  minio:
    profiles: [ "mlflow", "triton" ]
    image: "minio/minio:RELEASE.2022-04-12T06-55-35Z"
    container_name: minio
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.minio.rule=Host(`minio.127.0.0.1.nip.io`)"
      - "traefik.http.routers.minio.entrypoints=web"
      - "traefik.http.services.minio.loadbalancer.server.port=9001"
    restart: unless-stopped
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER
      - MINIO_ROOT_PASSWORD
    command: server /data --console-address ":9001"
    volumes:
      - minio_volume:/data
    networks:
      - mlops_bridge

  #########################################################################################

  # This service runs the postgres DB used by dagster for run storage, schedule storage,
  # and event log storage.
  dagster_postgres:
    profiles: [ "dagster" ]
    image: postgres:14
    container_name: dagster-postgres
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      POSTGRES_USER: $DAGSTER_POSTGRES_USER
      POSTGRES_PASSWORD: $DAGSTER_POSTGRES_PASSWORD
      POSTGRES_DB: $DAGSTER_POSTGRES_DB
    networks:
      - mlops_bridge

  # This service runs the gRPC server that loads your user code, in both dagit
  # and dagster-daemon. By setting DAGSTER_CURRENT_IMAGE to its own image, we tell the
  # run launcher to use this same image when launching runs in a new container as well.
  # Multiple containers like this can be deployed separately - each just needs to run on
  # its own port, and have its own entry in the workspace.yaml file that's loaded by dagit.
  dagster_repo:
    profiles: [ "dagster" ]
    build:
      context: .
      dockerfile: ./code/dagster-repo/Dockerfile
    container_name: dagster-repo
    image: $DAGSTER_CURRENT_IMAGE
    restart: always
    networks:
      - mlops_bridge
    environment:
      DAGSTER_POSTGRES_USER:
      DAGSTER_POSTGRES_PASSWORD:
      DAGSTER_POSTGRES_DB:
      DAGSTER_CURRENT_IMAGE:
      MINIO_ROOT_USER:
      MINIO_ROOT_PASSWORD:

  # This service runs dagit, which loads your user code from the user code container.
  # Since our instance uses the QueuedRunCoordinator, any runs submitted from dagit will be put on
  # a queue and later dequeued and launched by dagster-daemon.
  dagster_dagit:
    profiles: [ "dagster" ]
    build:
      context: .
      dockerfile: ./services/dagster/Dockerfile
    entrypoint:
      - dagit
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagster-dagit
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dagit.rule=Host(`dagit.127.0.0.1.nip.io`)"
      - "traefik.http.routers.dagit.entrypoints=web"
    expose:
      - "3000"
    ports:
      - "3000:3000"
    environment:
      - DAGSTER_POSTGRES_USER
      - DAGSTER_POSTGRES_PASSWORD
      - DAGSTER_POSTGRES_DB
    volumes:
      # Make docker client accessible so we can terminate containers from dagit
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - mlops_bridge
    depends_on:
      dagster_postgres:
        condition: service_healthy
      dagster_repo:
        condition: service_started

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    profiles: [ "dagster" ]
    build:
      context: .
      dockerfile: ./services/dagster/Dockerfile
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster-daemon
    restart: on-failure
    environment:
      - DAGSTER_POSTGRES_USER
      - DAGSTER_POSTGRES_PASSWORD
      - DAGSTER_POSTGRES_DB
    volumes:
      # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - mlops_bridge
    depends_on:
      - dagster_postgres
      - dagster_repo

  #########################################################################################

  mlflow_server:
    profiles: [ "mlflow" ]
    build:
      context: .
      dockerfile: ./services/mlflow/Dockerfile
      args:
        - MLFLOW_POSTGRES_USER
        - MLFLOW_POSTGRES_PASSWORD
        - MLFLOW_POSTGRES_DB
        - MLFLOW_S3_ENDPOINT_URL
        - MINIO_BUCKET_NAME
        - MINIO_ROOT_USER
        - MINIO_ROOT_PASSWORD

    container_name: mlflow-server
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.mlflow.rule=Host(`mlflow.127.0.0.1.nip.io`)"
      - "traefik.http.routers.mlflow.entrypoints=web"
    ports:
      - "4000:4000"
    networks:
      - mlops_bridge
    depends_on:
      - mlflow_minio
      - mlflow_postgres

  mlflow_postgres:
    profiles: [ "mlflow" ]
    image: postgres:14
    container_name: mlflow-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: $MLFLOW_POSTGRES_USER
      POSTGRES_PASSWORD: $MLFLOW_POSTGRES_PASSWORD
      POSTGRES_DB: $MLFLOW_POSTGRES_DB
    networks:
      - mlops_bridge

#########################################################################################

  triton_server:
      profiles: [ "triton" ]
      image: nvcr.io/nvidia/tritonserver:22.04-py3
      container_name: triton-server
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.triton.rule=Host(`triton.127.0.0.1.nip.io`)"
        - "traefik.http.routers.triton.entrypoints=web"
      ports:
        - "8000:8000"
        - "8001:8001"
        - "8002:8002"
      command: tritonserver --model-repository=/models
      networks:
        - mlops_bridge
      volumes:
        - triton_volume:/models
    

#########################################################################################
networks:
  mlops_bridge:
    name: "mlops_bridge"
    driver: bridge

volumes:
  minio_volume:
  triton_volume:
